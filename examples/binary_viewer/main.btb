#import "Logger"

#import "Array"
#import "Stream"
#import "Lexer"


fn main(argc: i32, argv: char**) -> i32 {
    // arguments
    // for 0..argc
    //     log(nr,argv[nr])
    TestSpec(); 
    
    // LexFile("examples/binary_viewer/spec.txt")

    // log(sizeof TypeDefinition)

    return 2;
}

fn TestSpec() {
    suc: bool;
    spec: FormatSpec;
    stream: ByteStream;
    defer {
        spec.cleanup();
        stream.cleanup();
    }

    // // Format description
    // spec.init();
    // spec.addField("all_size", TYPE_I32)
    // type_header := spec.createDefinition("Header")
    // spec.addField("magic", TYPE_I32, type_header)
    // spec.addField("section_count", TYPE_I32, type_header)
    // spec.addField("header",type_header)

    // // Test data
    // stream.reserve(0x1000);
    // suc = stream.write<i32>(5);
    // suc = stream.write<i32>(0x9932949);
    // suc = stream.write<i32>(92);
    // print_bytes(&stream);
    // Interpret(stream.sliced_unsafe(), &spec);
    
    suc = ParseSpecification("examples/binary_viewer/spec.txt", &spec);
    Interpret("examples/binary_viewer/data.txt", &spec);
}

enum FieldType {
    TYPE_NONE=0, // usually represents the fields in the specification itself
    TYPE_CHAR,
    TYPE_I8,
    TYPE_I16,
    TYPE_I32,
    TYPE_I64,
    TYPE_U8,
    TYPE_U16,
    TYPE_U32,
    TYPE_U64,
    TYPE_F32,
    TYPE_F64,

    TYPE_PRIMITIVE_COUNT,
}
struct Field {
    type: u32; // user defined struct or primitive
    count: u32;
    dynamic: bool; // dynamic based on another field, could be an expression?
    // value: u32; // index to the value data, stored in spec struct
    name: char[];
}
struct TypeDefinition {
    type: u32;
    size: u32;
    name: char[];

    fields: DynamicArray<Field>;
}
struct FormatSpec {
    fields: DynamicArray<Field>;
    definitions: DynamicArray<TypeDefinition>; // TODO: BucketArray

    fn init() {
        #define ADD(...) definitions.add(TypeDefinition{TYPE_##...});
        ADD(NONE, 0, "none")
        ADD(CHAR, 1, "char")
        
        ADD(I8  , 1, "i8")
        ADD(I16 , 2, "i16")
        ADD(I32 , 4, "i32")
        ADD(I64 , 8, "i64")

        ADD(U8  , 1, "u8")
        ADD(U16 , 2, "u16")
        ADD(U32 , 4, "u32")
        ADD(U64 , 8, "u64")

        ADD(F32 , 4, "f32")
        ADD(F64 , 8, "f64")
        #undef ADD
    }
    fn cleanup() {
        fields.cleanup();
        for @ptr definitions.sliced_unsafe()
            it.fields.cleanup();
        definitions.cleanup();
    }
    
    fn getDefinition(definition: u32) -> TypeDefinition* {
        return definitions.get_unsafe(definition);
    }
    fn createDefinition(name: char[]) -> u32 {
        def := definitions.add(TypeDefinition{});
        def.type = definitions.size() - 1;
        def.name = name;
        return def.type;
    }
    fn getField(definition: u32, fieldIndex: u32) -> Field* {
        // get_unsafe handles out of range
        if definition == 0 {
            return fields.get_unsafe(fieldIndex);
        }
        def := getDefinition(definition);
        return def.fields.get_unsafe(fieldIndex);
    }

    fn addField(name: char[], type: u32, definition: u32 = 0) {
        if definition == 0 {
            f := fields.add(Field{type});
            f.name = name;
        } else {
            def := getDefinition(definition);
            if def {
                f := def.fields.add(Field{type});
                f.name = name;
                typeDef := getDefinition(type);
                def.size += typeDef.size;
            } else
                pr("BAD, '",definition,"' is not a definition")
        }
    }
}

fn Interpret(path: char[], spec: FormatSpec*) {
    filesize: u64;
    file := FileOpen(&path, FILE_READ_ONLY, &filesize);
    if !file
        return;
        
    suc: bool;
    buffer: u8* = Allocate(filesize);
    defer Free(buffer, filesize);
    suc = FileRead(file, buffer, filesize);
    // TODO: Assert(suc)
    FileClose(file);
    
    Interpret(Slice<u8>{buffer, filesize}, spec);
}

// Prints the content of the stream based on the specification.
fn Interpret(stream: u8[], spec: FormatSpec*) {
    // TODO: The output should go through a standard logger with color and redirection support.
    //  Perhaps it's written to stdout, a file, and a StringBuilder.

    // Assert(spec)

    head: u32 = 0; // read head of stream

    struct Layer {
        type: u32 = 0; // 0 refers to specification
        fieldIndex: u32 = 0;
    }
    stack: DynamicArray<Layer>;
    stack.add(Layer{0, 0});

    pr("Interpret stream of ",stream.len," bytes\n")

    fn print_indent(indent: i32) {
        for 0..indent  printc(' ')
    }
    
    while stack.len {
        // get next field
        layer := stack.get_unsafe(stack.len - 1);

        element: Field* = spec.getField(layer.type, layer.fieldIndex);
        if !element {
            // log("pop",layer.type);
            stack.pop();
            continue;
        }
        elemDef := spec.getDefinition(element.type);
        layer.fieldIndex++;

        print_indent(stack.len-1);
        if element.name.ptr {
            pr(element.name,": ");
        } else {
            pr("<name>: ");
        }
        if element.type >= TYPE_PRIMITIVE_COUNT {
            // user defined field. make new stack
            // log("push",element.type);
            stack.add(Layer{element.type, 0});
        } else {
            if head + elemDef.size > stream.len {
                pr("abrupt end\n");
                // corruption somewhere
                break;
            }
            #multidefine CASE(E,T)
            case TYPE_##E: {
                tmp: T;
                memcpy(&tmp, stream.ptr + head, sizeof T);
                head += sizeof T;
                pr(tmp);
            }
            #enddef
            switch element.type {
            CASE(CHAR, char)

            CASE(I8, i8)
            CASE(I16, i16)
            CASE(I32, i32)
            CASE(I64, i64)

            CASE(U8, u8)
            CASE(U16, u16)
            CASE(U32, u32)
            CASE(U64, u64)

            CASE(F32, f32)
            CASE(F64, f64)
            case: {
                pr("UNREACHABLE_312")
            }
            }
                
        }
        pr(" (",elemDef.name,")");
        pr('\n');
    }
    pr("Finished, read ",head," bytes\n");
}


fn ParseSpecification(path: Slice<char>, out_spec: FormatSpec*) -> bool {
    out_spec.cleanup();
    out_spec.init();
    
    tokenStream := LexFile(path)
    defer DestroyTokenStream(tokenStream);
    if !tokenStream
        return false;
    
    parser: SpecParser;
    parser.tokens = tokenStream;
    parser.spec = out_spec;
    
    tokenStream.print();
    
    parser.parseBody();
    
    return true;
}
struct SpecParser {
    tokens: TokenStream*;
    spec: FormatSpec*;
    head: u32; // token index
    
    fn get(off: u32 = 0) -> Token* {
        return tokens.get(head + off);
    }
    fn consume(n: u32 = 1) {
        head += n;
    }
    
    fn parseBody() {
        
        while head < tokens.size() {
            tok := get();
            
            if tok.type == TOKEN_STRUCT {
                consume();
                parseStruct();
            }
            
            consume();
            log("BAD SYNTAX");
            tokens.print(head)
            pr("\n")
        }
    }
    fn parseStruct() {
        tok := get();
         
        if tok.type != TOKEN_STRUCT {
        }
        
        if tok.
        
        while head < tokens.size() {
            tok := get();
            
            consume();
            if tok.type != TOKEN_IDENTIFIER {
                log("BAD SYNTAX");
                tokens.print(head)
                pr("\n")
                continue;
            }
            
            consume();   
            if tok.type != ':' {
                log("BAD SYNTAX");
                tokens.print(head)
                pr("\n")
                continue;
            }
            
            
        }
    }
}