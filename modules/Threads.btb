/*
    Standard API for threads
    
    IMPORTANT: THREADS ARE NOT SUPPORTED IN THE VirtualMachine! yet?
*/

#import "Logger"

#if OS_WINDOWS
    #import "Windows"
#elif OS_LINUX
    #import "Linux"
#endif

/* Logic of compare and swap
if *ptr == old
    *ptr = new
    return old
else
    return *ptr
*/
fn @intrinsic atomic_compare_swap(ptr: i32*, old: i32, new: i32) -> i32;
fn @intrinsic atomic_add(ptr: i32*, value: i32) -> i32;
// TODO: atomic_add64?

struct Thread {
    os_handle: u64 = 0;
    id: u64 = 0;
    
    fn cleanup() {
        os_handle = 0
        id = 0
    }
    fn valid() -> bool {
        return id != 0
    }
}

// TODO: Implement @oscall which chooses convention based on targeted system.
// TODO: Windows threads returns integer while Linux threads return void*. Writing a program that works on both could be troublesome because of the different return value. How do deal with it?
#if OS_WINDOWS
#macro FnThread fn @stdcall (void*)->i32
#else
#macro FnThread fn @unixcall (void*)->void*
#endif

#macro ThreadId u64
// func should be fn @unixcall/@stdcall (void*) -> void*
fn ThreadCreate(func: FnThread, param: void*) -> Thread {
    // TODO: Handle error
    thread: Thread;
    #if OS_WINDOWS
        threadId: u32 = 0;
        thread.os_handle = cast_unsafe<u64>CreateThread(null, 0, func, param, null, &threadId);
        thread.id = threadId;
    #else
        threadId: u32 = 0;
        temp: pthread_t;
        err = pthread_create(&temp, null, func, param);
        thread.os_handle = cast_unsafe<u64>temp;
        thread.id = cast_unsafe<u64>temp;
    #endif
    return thread;
}
// fn ThreadDestroy(thread: Thread) {
//     // TODO: Handle error
//     #if OS_WINDOWS
//         CloseHandle(thread.os_handle);
//     #else
//         ThreadJoin(thread); // nocheckin TODO: temporary
//     #endif
// }
fn ThreadJoin(thread: Thread) {
    // TODO: Handle error
    #if OS_WINDOWS
        WaitForSingleObject(thread.os_handle, 0xFFFFFFFF); // 0xFFFFFFFF wait indefinitely
        CloseHandle(thread.os_handle);
    #else
        // Assert(sizeof(pthread) == sizeof(thread.os_handle));
        err = pthread_join(cast_unsafe<pthread_t>thread.os_handle, cast_unsafe<void**>null);
    #endif
}
fn ThreadSelfId() -> ThreadId {
    #if OS_WINDOWS
        return GetCurrentThreadId();
    #else
        return cast_unsafe<u64>pthread_self();
    #endif
}

#macro INTERNAL_TO_OS_HANDLE(N) (cast<u64>(N) + 1)
#macro OS_HANDLE_TO_INTERNAL(N) (cast<void*>((N) - 1))

struct Mutex {
    os_handle: u64;
    _owner_thread: ThreadId; // implementation may change, keep member private for now

    fn cleanup() {
        if os_handle != 0 {
            yes := CloseHandle(os_handle - 1)
            if !yes {
                err := GetLastError();
                log("[WinError ",err,"] CloseHandle");
            }
            os_handle = 0
        }
    }
    fn lock() {
        // log("LOCKING")
        if os_handle == 0 {
            handle := CreateMutexA(null, false, null);
            if handle == INVALID_HANDLE_VALUE {
                err := GetLastError();
                log("[WinError ",err,"] CreateMutex");
            } else
                os_handle = INTERNAL_TO_OS_HANDLE(handle)
        }
        if os_handle != 0 {
            res := WaitForSingleObject(OS_HANDLE_TO_INTERNAL(os_handle), INFINITE)
            newId := ThreadSelfId()
            owner := _owner_thread
            // log("Lock ",newId," ",os_handle);
            if (owner != 0) {
                log("Mutex : Locking twice, old owner: ",owner,", new owner: ",newId)
            }
            _owner_thread = newId;
            if res == WAIT_FAILED {
                // TODO: What happened do the old thread who locked the mutex. Was it okay to ownerThread = newId
                err := GetLastError();
                log("[WinError ",err,"] WaitForSingleObject");
            }
        }
    }
    fn unlock() {
        if os_handle != 0 {
            // log("Unlock ",_owner_thread," ", os_handle);
            _owner_thread = 0;
            yes := ReleaseMutex(OS_HANDLE_TO_INTERNAL(os_handle))
            if !yes {
                err := GetLastError();
                log("[WinError ",err,"] ReleaseMutex");
            }
        }
    }
    fn getOwner() {
        return _owner_thread
    }
}

struct Semaphore {
    fn init(initial: u32, maxLocks: u32) {
        m_initial = initial
        m_max = maxLocks

        handle := CreateSemaphoreA(null, m_initial, m_max, null);
		if (handle == INVALID_HANDLE_VALUE) {
			err := GetLastError();
			log("[WinError ",err,"] CreateSemaphore");
		} else {
			os_handle = INTERNAL_TO_OS_HANDLE(handle);
		}
    }
    fn cleanup() {
        if (os_handle != 0){
            yes := CloseHandle(OS_HANDLE_TO_INTERNAL(os_handle));
            if(!yes){
                err := GetLastError();
                log("[WinError ",err,"] CloseHandle");
            }
            os_handle = 0
        }
    }

    fn wait() {
        if (os_handle == 0) {
			handle := CreateSemaphoreA(null, m_initial, m_max, null);
			if (handle == INVALID_HANDLE_VALUE) {
				err := GetLastError();
                log("[WinError ",err,"] CreateSemaphore");
			} else {
                os_handle = INTERNAL_TO_OS_HANDLE(handle);
			}
		}
		if (os_handle != 0) {
			res := WaitForSingleObject(OS_HANDLE_TO_INTERNAL(os_handle), INFINITE);
			if (res == WAIT_FAILED) {
				err := GetLastError();
				log("[WinError ",err,"] WaitForSingleObject");
			}
		}
    }
    // count is how much to increase the semaphore's count by.
    fn signal(count: i32 = 1) {
        // MEASURE
		if (os_handle != 0) {
			yes := ReleaseSemaphore(INTERNAL_TO_OS_HANDLE(os_handle), count, null);
			if (!yes) {
				err := GetLastError();
				// if(err == ERROR_TOO_MANY_POSTS)
				// 	PL_PRINTF("[WinError %lu] ReleaseSemaphore, to many posts\n",err);
				// else
					log("[WinError ",err,"] ReleaseSemaphore");
			}
		}
    }

    m_initial: u32 = 1;
    m_max: u32 = 1;

    os_handle: u64; // Windows

    // TODO: Linux
    // static const int SEM_SIZE = 32;
    // u8 m_data[SEM_SIZE]; // sem_t
    // bool m_initialized;
}